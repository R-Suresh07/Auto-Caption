{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33cc2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "from deep_translator import GoogleTranslator\n",
    "from pytube import YouTube\n",
    "import ffmpeg\n",
    "import pandas as pd\n",
    "import os\n",
    "import moviepy.editor as mp\n",
    "from moviepy.editor import *\n",
    "import cv2\n",
    "from moviepy.video.tools.subtitles import SubtitlesClip\n",
    "from moviepy.config import change_settings\n",
    "change_settings({\"IMAGEMAGICK_BINARY\": r\"C:\\Program Files\\ImageMagick-7.1.1-Q16-HDRI\\magick.exe\"})\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = whisper.load_model(\"medium\",download_root=r\"D:\\WHISPER MODELS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99b673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transcriptor:\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    def __init__(self,audio):\n",
    "        # load audio and pad/trim it to fit 30 seconds\n",
    "        self.audio=whisper.pad_or_trim(audio)\n",
    "        # make log-Mel spectrogram and move to the same device as the model\n",
    "        self.mel=whisper.log_mel_spectrogram(self.audio).to(DEVICE)\n",
    "    def detect_language(self):\n",
    "        # detect the spoken language\n",
    "        mel=self.mel\n",
    "        _, probs = model.detect_language(mel)\n",
    "        print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "        return(max(probs, key=probs.get))\n",
    "    def transcribe(self):\n",
    "        # decode the audio and print the recognized text\n",
    "        mel=self.mel\n",
    "        self.detect_language()\n",
    "        options = whisper.DecodingOptions(fp16=False)\n",
    "        result = whisper.decode(model,mel, options)\n",
    "        print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "682a21bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Translator:\n",
    "    def __init__(self):\n",
    "        self.name=input(\"Name of the project: \")\n",
    "        self.uploaded_vid=input(\"Path of the video file you want to translate: \")\n",
    "        self.input_file=input(\"Name of the video file along with the extension: \")\n",
    "        self.audio_file=input(\"Name of the audio file: \")\n",
    "        self.output_name=input(\"Name of the captioned video: \")\n",
    "        path=f\"D:\\captiontesting\\{self.name}\"\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            print(f\"{self.name} created.\")\n",
    "        my_clip = mp.VideoFileClip(self.uploaded_vid)\n",
    "        my_clip.write_videofile(f'D:/captiontesting/{self.name}/{self.input_file}')\n",
    "        audio_file_path=f\"D:/captiontesting/{self.name}/{self.audio_file}\"\n",
    "        my_clip.audio.write_audiofile(audio_file_path)\n",
    "        print(\"Starting Transcription\")\n",
    "        self.result=model.transcribe(audio_file_path,task='translate',fp16=False)\n",
    "        self.untranslated=self.result['text']\n",
    "        self.language=\"\"\n",
    "        self.translated=\"\"\n",
    "        print(\"Transcription done successfully!\")\n",
    "    def find_language(self):\n",
    "        temp=whisper.load_audio(f\"D:/captiontesting/{self.name}/{self.audio_file}\")\n",
    "        test1=Transcriptor(temp)\n",
    "        self.language=test1.detect_language()\n",
    "    def convert_to_tamil(self):\n",
    "        if self.language==\"ta\":\n",
    "            print(\"Already in Tamil\")\n",
    "        else:\n",
    "            self.language=\"ta\"\n",
    "            self.translated=GoogleTranslator(source=\"en\", target=\"ta\").translate(self.untranslated)\n",
    "    def caption(self):\n",
    "        name=self.name\n",
    "        input_file=self.input_file\n",
    "        dict1 = {'start':[], 'end':[], 'text':[]}\n",
    "        for i in self.result['segments']:\n",
    "            dict1['start'].append(int(i['start']))\n",
    "            dict1['end'].append(int(i['end']))\n",
    "            dict1['text'].append(i['text'])\n",
    "        df = pd.DataFrame.from_dict(dict1)\n",
    "        vidcap = cv2.VideoCapture(f'D:/captiontesting/{self.name}/{self.input_file}')\n",
    "        success,image = vidcap.read()\n",
    "        height = image.shape[0]\n",
    "        width =image.shape[1]\n",
    "        generator = lambda txt: TextClip(txt, font='P052-Bold', fontsize=width/50, stroke_width=.7, color='white', stroke_color = 'black', size = (width, height*.25), method='caption')\n",
    "        subs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\n",
    "        subtitles = SubtitlesClip(subs, generator)\n",
    "        video = VideoFileClip(self.uploaded_vid)\n",
    "        final = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\n",
    "        final.write_videofile(f'D:/captiontesting/{self.name}/{self.output_name}', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n",
    "        print(\"File captioned successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d178bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the project: epics\n",
      "Path of the video file you want to translate: C:\\Users\\Suresh\\Desktop\\EPICS TESTING\\out.mp4\n",
      "Name of the video file along with the extension: russia_ukraine.mp4\n",
      "Name of the audio file: russia_ukraine.mp3\n",
      "Name of the captioned video: captioned_russia_ukraine.mp4\n",
      "epics created.\n",
      "Moviepy - Building video D:/captiontesting/epics/russia_ukraine.mp4.\n",
      "MoviePy - Writing audio in russia_ukraineTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video D:/captiontesting/epics/russia_ukraine.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready D:/captiontesting/epics/russia_ukraine.mp4\n",
      "MoviePy - Writing audio in D:/captiontesting/epics/russia_ukraine.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Starting Transcription\n",
      "Transcription done successfully!\n"
     ]
    }
   ],
   "source": [
    "ct2=Custom_Translator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dffa1662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video D:/captiontesting/epics/captioned_russia_ukraine.mp4.\n",
      "MoviePy - Writing audio in captioned_russia_ukraineTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video D:/captiontesting/epics/captioned_russia_ukraine.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready D:/captiontesting/epics/captioned_russia_ukraine.mp4\n",
      "File captioned successfully\n"
     ]
    }
   ],
   "source": [
    "ct2.caption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca8aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
